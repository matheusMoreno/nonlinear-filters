\chapter{Filtro de Wiener}
\label{chapter:wiener}

Começaremos nossa análise de métodos de identificação com o Filtro de Wiener~\cite{hayes-1996}. Mais especificamente, usaremos uma versão do modelo que contempla apenas distorções lineares na estimação: como sua saída é computada por meio de uma convolução linear entre o filtro calculado e a entrada, definiremos esta como sendo o sinal original. Assim, o algoritmo será incapaz de introduzir harmônicos na entrada, e, portanto, seu desempenho no contexto do projeto será limitado. Todavia, como um método não-linear deve ser capaz de reproduzir linearidades, os resultados deste capítulo servirão como valores de referência nas análises dos demais métodos.

Desenvolvido por Norbert Wiener durante os anos 1940~\cite{wiener-1949}, o Filtro de Wiener ganhou notoriedade por sua simplicidade e robustez, sendo um dos primeiros métodos a adotar uma abordagem estatística em sua modelagem. Ele é caracterizado por ser um \emph{filtro linear ótimo} para o erro quadrático médio entre o sinal observado e o estimado. Curiosamente, o pesquisador soviético Andrei Kolmogorov desenvolveu independentemente as equações do filtro para sinais discretos, publicando seu trabalho em 1941~\cite{kolmogorov-1941}; por este motivo, o método é algumas vezes chamado de Filtro de Wiener-Kolmogorov, embora esta seja uma alcunha muito mais rara.

Este capítulo se inicia formulando o problema a ser considerado. Então, o Filtro de Wiener FIR (de \textit{Finite-length Impulse Response}, ou Resposta ao Impulso de Comprimento Finito) para sinais discretos será formalmente deduzido e suas equações serão apresentadas. Em seguida, o algoritmo específico aplicado no trabalho será explicitado, e seu desempenho será avaliado com uma série de experimentos em sinais de áudio com distorções lineares e/ou não-lineares.

\section{Formulação do problema}
\label{section:wiener:wiener-model}

O Filtro de Wiener pode ser empregado, dentre outras aplicações, para predição linear, cancelamento de ruído, ou, como no caso do trabalho em questão, estimação de um sinal filtrado. Seja qual for o contexto, o cerne do problema é sempre o mesmo: encontrar um filtro que minimize o erro quadrático médio entre sua saída e um sinal desejado.

Abstraindo a terminologia apresentada no Capítulo~\ref{chapter:intro}, considere o sinal de referência $d[n]$ e o sinal observado $x[n]$. Supõe-se que ambos são amostras de sequências aleatórias estacionárias no sentido amplo (WSS\abbrev{WSS}{\textit{Wide-Sense Stationary}}, de \textit{Wide-Sense Stationary})~\cite{peebles-1987}. Nosso objetivo é encontrar o filtro $W(z)$\symbl{$W(z)$}{Transformada Z do Filtro de Wiener} com resposta ao impulso $w[n]$\symbl{$w{[n]}$}{Resposta ao impulso do Filtro de Wiener}, tal que a estimativa dada pela convolução linear entre $x[n]$ e $w[n]$,
\begin{equation}
    \hat{d}[n] = (w * x)[n]\symbl{$*$}{Convolução entre dois sinais},
\end{equation}
minimize o erro quadrático médio entre $d[n]$ e $\hat{d}[n]$,
\begin{equation}
    \xi = E\{|e[n]|^2\} = E\{|d[n] - \hat{d}[n]|^2\},
    \label{eq:wf:square-error}
\end{equation}
onde $E\{\cdot\}$\symbl{$E\{\cdot\}$}{Valor esperado estatístico} é o valor esperado estatístico e $e[n] = d[n] - \hat{d}[n]$\symbl{$e{[n]}$}{Erro entre a saída observada e a estimada} é o erro entre a saída obtida e a referência. Como pressupomos que tanto $x[n]$ quanto $d[n]$ são WSS, $\xi$\symbl{$\xi$}{Erro quadrático médio entre a observação e a estimação} é um valor constante para um dado $W(z)$ e, portanto, independente de $n$. Um diagrama de blocos do problema encontra-se na Figura~\ref{fig:wf:sistem-model}. A elaboração foi feita no domínio discreto; a reformulação para sinais contínuos, porém, é imediata.
\begin{figure}[!ht]
    \centering
    \input{images/wiener/system-model}
    \caption[Diagrama de blocos do problema para o Filtro de Wiener]{Diagrama de blocos do problema para o Filtro de Wiener.}
    \label{fig:wf:sistem-model}
\end{figure}

No problema originalmente proposto por Wiener, $x[n]$ é a versão corrompida por ruído aditivo de uma referência $d[n]$. No nosso caso, alguns papéis foram trocados: $x[n]$ é um sinal não-distorcido, e queremos reproduzir as distorções presentes em $d[n]$; este sinal, porém, está indisponível, e temos apenas $y[n]$, a observação. Esta diferença conceitual não afeta a derivação das equações do filtro, e retornaremos à terminologia do trabalho quando o método específico for proposto.

\section{Filtro de Wiener FIR causal}
\label{section:wiener:fir-filter}

Com o problema bem definido, devemos agora discorrer sobre como solucioná-lo. Note que, na formulação, não foram especificadas as características do filtro ótimo (além de ele ser discreto, embora tenha sido mencionado seu equivalente contínuo). Isto não foi por acaso; é possível desenvolver diferentes soluções para o filtro, dependendo das restrições impostas: se ele será causal ou não-causal, discreto ou contínuo, e com resposta ao impulso de duração finita ou não.

Neste trabalho, foi estipulado o uso do Filtro de Wiener FIR discreto e causal, visto que este é relativamente simples de ser derivado e implementado, além de ser suficientemente eficaz para uma primeira análise do problema de estimação. Ademais, como estamos tratando de sinais digitais, é natural a escolha de um filtro discreto. Suas equações serão agora desenvolvidas.

Para esta derivação, além das suposições apresentadas na Seção~\ref{section:wiener:wiener-model}, consideraremos também que os sinais $x[n]$ e $d[n]$ são conjuntamente estacionários no sentido amplo, e que sua correlação cruzada $R_{xd}[k]$\symbl{$R_{\cdot\cdot}{[k]}$}{Autocorrelação ou correlação cruzada} é conhecida, além de $R_{xx}[k]$, a autocorrelação de $x[n]$. Pressupõe-se também que todos os sinais são reais.

Se o filtro projetado tem resposta ao impulso finita e é causal, isto significa que sua Transformada Z é da forma
\begin{equation}
    W(z) = \sum_{n=0}^{L-1} w[n] z^{-n},
\end{equation}
onde $L$\symbl{$L$}{Tamanho do filtro utilizado} é o comprimento do filtro. Além disso,
\begin{equation}
    \hat{d}[n] = (w * x)[n] = \sum_{m = 0}^{L - 1} w[m] x[n - m].
    \label{eq:wf:dhat-conv}
\end{equation}

É possível reescrever esta última equação na forma de uma operação matricial. Para isso, considere o vetor $\mathbf{w}$, composto pelos coeficientes do filtro,
\begin{equation}
    \mathbf{w} = \begin{bmatrix} w[0] & w[1] & \cdots & w[L - 1] \end{bmatrix}^T,
    \symbl{$\mathbf{w}$}{Vetor com os coeficientes do Filtro de Wiener}
\end{equation}
e o vetor $\mathbf{x}[n]$, que contém as últimas $L$ amostras de $x[n]$,
\begin{equation}
    \mathbf{x}[n] = \begin{bmatrix} x[n] & x[n-1] & \cdots & x[n - L + 1] \end{bmatrix}^T.
    \symbl{$\mathbf{x}{[n]}$}{Vetor com as últimas $L$ amostras de $x{[n]}$}
    \label{eq:wf:xn-vector}
\end{equation}
Assim, a Equação~\eqref{eq:wf:dhat-conv} pode ser reformulada como $\hat{d}[n] = \mathbf{w}^T \mathbf{x}[n]$. Então, o erro quadrático médio entre a sinal observado e a saída estimada será
\begin{align}
    \xi &= E\{ e[n]^2 \} = E\{ (d[n] - \hat{d}[n])^2 \} \\
    &= E\{ (d[n] - \mathbf{w}^T \mathbf{x}[n]) (d[n] - \mathbf{w}^T \mathbf{x}[n]) \} \\
    &= E\{ d^2[n] - 2 d[n] \mathbf{w}^T \mathbf{x}[n] + \mathbf{w}^T \mathbf{x}[n]\mathbf{w}^T \mathbf{x}[n] \} \label{eq:wf:err-step2} \\
    &= E\{ d^2[n] - 2 d[n] \mathbf{w}^T \mathbf{x}[n] + \mathbf{w}^T \mathbf{x}[n] \mathbf{x}[n]^T \mathbf{w} \} \label{eq:wf:err-step3} \\
    &= E\{ d^2[n] \} - 2 \mathbf{w}^T E\{ d[n] \mathbf{x}[n] \} + \mathbf{w}^T E\{ \mathbf{x}[n] \mathbf{x}[n]^T \} \mathbf{w} \label{eq:wf:err-step4}.
\end{align}

As Equações~\eqref{eq:wf:err-step2} e~\eqref{eq:wf:err-step3} são equivalentes pois, como $\mathbf{w}$ e $\mathbf{x}[n]$ estão ambos em $\mathbb{R}^L$, $\mathbf{w}^T \mathbf{x}[n] = \mathbf{x}[n]^T \mathbf{w}$. Ademais, como o operador de valor esperado é linear, podemos aplicá-lo individualmente em cada um dos termos da soma, extraindo os termos constantes (determinísticos) da operação no processo.

A função objetivo que se deseja minimizar é $\xi(\mathbf{w})$\footnote{Anteriormente, afirmamos que $\xi$ era constante para determinado $W(z)$; isso ainda é verdade para um dado $\mathbf{w}$.}. Esta, por sua vez, é quadrática em relação a $\mathbf{w}$. Portanto, $\xi(\mathbf{w})$ possui um mínimo global, que pode ser achado calculando-se o valor de $\mathbf{w}$ no qual o gradiente $\nabla \xi(\mathbf{w})$\symbl{$\nabla$}{Operador gradiente} é igual a um vetor nulo~\cite{diniz-2020}. Vamos formalizar esta linha de raciocínio.

Para encontrar os coeficientes do filtro ótimo, que denominaremos $\mathbf{w}^*$\symbl{$\mathbf{w}^*$}{Coeficientes ótimos do Filtro de Wiener}, devemos desenvolver a expressão do gradiente de $\xi(\mathbf{w})$,
\begin{equation}
    \nabla\xi(\mathbf{w}) = \begin{bmatrix} \displaystyle \frac{\partial \xi}{\partial w_1} & \displaystyle \frac{\partial \xi}{\partial w_2} & \cdots & \displaystyle \frac{\partial \xi}{\partial w_L} \end{bmatrix}^T,
\end{equation}
e igualá-la a um vetor nulo; o valor de $\mathbf{w}$ resultante será $\mathbf{w}^*$, ou seja,
\begin{equation}
    \argmin_{\mathbf{w}} \xi(\mathbf{w}) = \mathbf{w}^* \iff \nabla\xi(\mathbf{w}^*) = \mathbf{0}.
    \label{eq:wf:coef-iff}
\end{equation}

O gradiente do erro quadrático médio pode ser facilmente calculado consideran-\\do-se as propriedades de cálculo vetorial~\cite{matrix-cookbook}; com isso, encontramos que
\begin{equation}
    \nabla \xi(\mathbf{w}) = \mathbf{0} - 2 E\{ d[n] \mathbf{x}[n] \} + 2 E\{\mathbf{x}[n]\mathbf{x}[n]^T\} \mathbf{w},
\end{equation}
visto que $\mathbf{x}[n]\mathbf{x}[n]^T$ é uma matriz simedida e, consequentemente, $E\{\mathbf{x}[n]\mathbf{x}[n]^T\}$ também será. Considerando o lado esquerdo da Expressão~\eqref{eq:wf:coef-iff}, temos então que
\begin{equation}
    \nabla\xi(\mathbf{w}^*) = \mathbf{0} \implies E\{\mathbf{x}[n]\mathbf{x}[n]^T\} \mathbf{w}^* = E\{ d[n] \mathbf{x}[n] \}.
    \label{eq:wf:implies}
\end{equation}

Estamos próximos do resultado desejado; porém, é possível simplificar a equação final com algumas definições. Primeiramente, note que o elemento na $i$-ésima linha e $j$-ésima coluna de $E\{\mathbf{x}[n]\mathbf{x}[n]^T\}$ é dado por
\begin{equation}
    E\{x[n-i+1]x[n-j+1]\} = R_{xx}[i - j].
\end{equation}
Assim, podemos definir a \emph{matriz de autocorrelação} de $x[n]$ como sendo
\begin{equation}
    \mathbf{R}_{xx} = E\{\mathbf{x}[n]\mathbf{x}[n]^T\} = \begin{bmatrix}
    R_{xx}[0] & R_{xx}[1] & \cdots & R_{xx}[L - 1] \\
    R_{xx}[1] & R_{xx}[0] & \cdots & R_{xx}[L-2] \\
    \vdots & \vdots & \ddots & \vdots \\
    R_{xx}[L - 1] & R_{xx}[L - 2] & \cdots & R_{xx}[0]
    \end{bmatrix}.
    \symbl{$\mathbf{R}_{\cdot\cdot}$}{Matriz de autocorrelação ou correlação cruzada}
    \label{eq:wf:autocorr-matrix}
\end{equation}

Da mesma forma, define-se também um \emph{vetor de correlação cruzada} entre $x[n]$ e $d[n]$ como sendo
\begin{equation}
    \mathbf{r}_{xd} = E\{ d[n] \mathbf{x}[n] \} = \begin{bmatrix}
    R_{xd}[0] & R_{xd}[1] & \cdots & R_{xd}[L-1]
    \end{bmatrix}^T.
    \symbl{$\mathbf{r}_{\cdot\cdot}$}{Vetor de autocorrelação ou correlação cruzada}
    \label{eq:wf:corr-vector}
\end{equation}

Considerando as Equações~\eqref{eq:wf:autocorr-matrix} e~\eqref{eq:wf:corr-vector}, a equação à esquerda da Relação~\eqref{eq:wf:implies} pode ser reescrita como uma simples equação do tipo $\mathbf{A}\mathbf{x} = \mathbf{b}$; assim, encontramos a fórmula que descreve os coeficientes do filtro ótimo:
\begin{equation}
    \mathbf{R}_{xx} \mathbf{w}^* = \mathbf{r}_{xd} \implies \mathbf{w}^* = \mathbf{R}_{xx}^{-1} \mathbf{r}_{xd}.
\end{equation}

É interessante notar que, em casos práticos (por exemplo, o problema contemplado neste trabalho), temos apenas uma realização de cada sinal (a entrada e a referência), de tal modo que é preciso pressupor que estes são ergódicos e estimar o comportamento de $R_{xx}[k]$ e $R_{xd}[k]$ utilizando todas as amostras disponíveis. Assim, mesmo o filtro sendo causal, todas as amostras de $x[n]$ e $d[n]$ contribuem para o valor de $\hat{d}[n]$ em um instante $n$. Sendo $N$\symbl{$N$}{Número total de amostras no sinal} é o número total de amostras dos sinais considerados, o estimador (enviesado) usado para aproximar a função de autocorrelação de $x[n]$ é descrito pela equação
\begin{equation}
    \hat{R}_{xx}[k] = \frac{1}{N} \sum_{i=k}^{N-1} x[i] x[i-k].
\end{equation}
O estimador usado para a função $R_{xd}[k]$ é definido de forma similar.

\section{Método proposto}
\label{section:wiener:method}

Para se aplicar o Filtro de Wiener no contexto do trabalho, algumas adaptações precisam ser feitas. Como gravações sonoras não costumam ser estacionárias, foi estipulado que a estimação será feita usando a técnica \textit{overlap-add}. Desse modo, durante cada intervalo considerado, pressupõe-se estacionariedade e, assim, são calculados o filtro e a saída correspondentes; então, as saídas individuais de cada intervalo são combinadas para gerar a estimação final. Este método pode ser interpretado como um filtro adaptativo em que os coeficientes são atualizados a cada intervalo. A partir de agora, usaremos $y[n]$ em vez de $d[n]$ como sinal desejado, já que, na prática, usaremos a observação no método.

A Figura~\ref{fig:wf:overlap-add} ilustra os passos da técnica para a $i$-ésima iteração. Considerando que o algoritmo encontra-se na amostra $k$, os próximos $M$\symbl{$M$}{Tamanho total do intervalo considerado (e da janela) em uma iteração da estimação} valores de $x[n]$ e $y[n]$ são utilizados, ou seja, $M$ é o tamanho do intervalo. Com isso, definem-se os sinais auxiliares $x_i[n]$\symbl{$x_i{[n]}$}{Versão truncada do sinal original a ser usada na $i$-ésima iteração do método de estimação} e $y_i[n]$\symbl{$y_i{[n]}$}{Versão truncada da observação a ser usada na $i$-ésima iteração do método de estimação}, que nada mais são do que sinais de duração $M$ compostos pelas amostras atualmente avaliadas; com eles, os coeficientes do $i$-ésimo filtro são estimados. Então, uma janela $h[n]$\symbl{$h{[n]}$}{Função de janelamento utilizada na estimação} (de tamanho $M$) é aplicada a $x_i[n]$, e o sinal resultante é filtrado no domínio da frequência (por esse motivo, é interessante que $M = 2^p$, $p \in \mathbb{N}^*$, para otimizar o cálculo da FFT\abbrev{FFT}{\textit{Fast Fourier Transform}}, requerendo que $w_i[n]$\symbl{$w_i{[n]}$}{Resposta ao impulso do Filtro de Wiener calculado na $i$-ésima iteração do método de estimação} receba um \textit{zero padding} de $M - L$ amostras). Depois da filtragem, calcula-se a transformada inversa do bloco, aplica-se novo janelamento, e o resultado é somado à estimativa final. Então, saltamos $H$\symbl{$H$}{Tamanho do salto entre uma iteração e outra do método de estimação} amostras para a próxima iteração; deste modo, um intervalo usa as últimas $M-H$ amostras do intervalo anterior, e cada iteração do algoritmo começa em um índice múltiplo de $H$ (ou seja, $k = Hi$, $i \in \mathbb{N}$). Para que o processamento faça sentido, $0 < H \leq M$.
\begin{figure}
    \centering
    \input{images/wiener/overlap-add}
    \caption[Ilustração do método utilizado no Filtro de Wiener]{Ilustração da técnica \textit{overlap-add}, utilizada na implementação prática do Filtro de Wiener, para a $i$-ésima iteração.}
    \label{fig:wf:overlap-add}
\end{figure}

Por que usar duas janelas no método? No caso da análise (antes da transformada), aplicar uma janela adequada pode reduzir o vazamento espectral (\textit{spectral leakage}) que ocorre ao limitarmos o intervalo de análise do sinal a apenas $M$ amostras. Já o janelamento aplicado na etapa de síntese (depois da transformada inversa) ajuda a atenuar variações agressivas próximas às bordas do bloco filtrado e propicia uma transição gradual entre intervalos na estimação final. Uma condição importante a que devemos nos ater é a de \textit{constant overlap-add} (COLA\abbrev{COLA}{\textit{Constant Overlap-Add}})~\cite{bosi-2002}: a soma de várias janelas de comprimento $M$ com sobreposição $M-H$ deve resultar em um valor constante para que não seja introduzido uma modulação indesejada na estimação final. Na realidade, como estamos aplicando uma janela duas vezes, é necessário que sua \emph{versão quadrática} satisfaça essa condição.

\section{Experimentos}
\label{section:wf:experiments}

Os experimentos foram realizados a partir de duas faixas de áudio. Como sinal original $x[n]$, foi selecionada uma trilha de 15 segundos composta pelo som da flauta chinesa hulusi~\cite{wiener-reference-source}; já como ruído $r[n]$, foi utilizada parte de um diálogo de uma leitura dramática de \textit{Mansfield Park}, de Jane Austen~\cite{wiener-dialogue-source}, totalizando 12 segundos. Ambas as gravações foram pré-condicionadas a serem mono (no caso de uma gravação estéreo, extraiu-se a faixa da esquerda), com taxa de amostragem de 44.1 kHz e profundidade de bit (\textit{bitdepth}) de 16 bits. Além disso, as duas faixas receberam um ganho de normalização, fazendo com que seus valores máximos de amplitude alcançassem 0~dB (em outras palavras, $\max \left| x[n] \right| = 1$). As Figuras~\ref{fig:wf:spectogram-reference} e~\ref{fig:wf:spectogram-dialogue} apresentam os espectrogramas do sinal original e do ruído, respectivamente.
\begin{figure}[!ht]
    \centering
    \includegraphics[width=\linewidth]{wiener/wiener-reference-signal.eps}
    \caption[Espetrograma do sinal original usado nos experimentos]{Espectrograma do sinal original utilizado nos experimentos.}
    \label{fig:wf:spectogram-reference}
\end{figure}
\begin{figure}[!ht]
    \centering
    \includegraphics[width=\linewidth]{wiener/wiener-dialogue-signal.eps}
    \caption[Espetrograma do ruído usado nos experimentos]{Espectrograma da gravação de diálogo (a ser interpretada como ruído) utilizada nos experimentos.}
    \label{fig:wf:spectogram-dialogue}
\end{figure}

Em relação à janela escolhida para o método de \textit{overlap-add}, foi priorizado um janelamento que aplicasse ganho unitário ao sinal sintetizado, para que não fosse necessário um pós-processamento de correção de ganho. Nas devidas condições, a função de Hann de comprimento $M$ definida como
\begin{equation}
    h^2[n] = \frac{1}{2} - \frac{1}{2}\cos\left(\frac{2\pi n}{M}\right) = \sen^2\left( \frac{\pi n}{M} \right),\ 0 \leq n \leq M-1,
\end{equation}
cumpre esse requisito: com $M$ par, uma sobreposição de $50\%$ ($H = M/2$) resulta em \textit{overlap-add} constante com ganho unitário~\cite{heinzel-2002}. Por este motivo, a janela estipulada foi escolhida com base na função de Hann. Porém, como explicitado na seção anterior, o janelamento será aplicado duas vezes ao sinal, e, portanto, precisamos de que sua versão quadrática satisfaça a condição de COLA. Assim, a janela $h[n]$ que foi usada é a raiz quadrada da descrita anteriormente:
\begin{equation}
    h[n] = \sqrt{\frac{1}{2} - \frac{1}{2}\cos\left(\frac{2\pi n}{M}\right)} = \sen\left( \frac{\pi n}{M} \right),\ 0 \leq n \leq  M-1.
\end{equation}

Todos os experimentos foram executados com filtros de tamanho $L = 34$, janelas de comprimento $M = 2^{13} = 8192$ (aproximadamente $186$ ms), e, consequentemente, saltos de $H = 4096$ amostras. Estes parâmetros foram definidos após múltiplos testes com diferentes valores terem sido realizados. Tais escolhas apresentaram o melhor resultado geral.

\subsection{\textit{Fades}}

Para o primeiro experimento, o sinal distorcido foi gerado aplicando-se um \textit{fade-out} e um \textit{fade-in} no início e no final, respectivamente, da gravação original. Para isso, foi utilizada a ferramenta de envoltória do Audacity, na qual a transição entre ganhos é feita seguindo uma curva exponencial. Para o \textit{fade-out}, os parâmetros do ganho foram $A_\mathrm{i} = 1$ e $A_\mathrm{f} = 0.2$. Similarmente, no \textit{fade-in} estes parâmetros foram $A_\mathrm{i} = 0.2$ e $A_\mathrm{f} = 1$. Ambos os efeitos duraram aproximadamente 1.5 segundo. O ruído não foi adicionado à mixagem final. Assim, avaliamos a capacidade do método em estimar o processamento de um sistema linear variante no tempo. Os resultados encontram-se na Tabela~\ref{tab:wf:experiment-1}.
{\def\arraystretch{1.25}\tabcolsep=10pt
\begin{table}[!ht]
    \centering
    \caption[Resultados do primeiro experimento: \textit{fades}]{Resultados do primeiro experimento.}
    \label{tab:wf:experiment-1}
    \begin{tabular}{cccc}
        \toprule
                         & SDR        & PAQM (MOS)   & $\log_{10}(R_{\text{nonlin}})$ \\
        \midrule
        $(d, x)$       & $-11.57$ dB & $1.17$  & $-0.005$                 \\
        $(d, \hat{d})$ & $42.65$ dB & $2.04$   & $-0.006$                \\ \bottomrule
    \end{tabular}
\end{table}
}

Ao observarmos apenas os resultados da SDR, podemos concluir que o método estimou de forma satisfatória a distorção que foi aplicada à gravação original. Por outro lado, se considerarmos apenas a PAQM, a melhoria não parece ter sido tão satisfatória assim. Porém, não podemos nos esquecer que a rigorosa compressão aplicada pela transformação dos resultados de $\log_{10}(\mathcal{L}_n)$ em MOS pode resultar em valores baixos mesmo em sinais muito similares. Assim, não podemos nos ater apenas ao valor absoluto do resultado, e sim interpretá-lo no contexto geral; neste caso, a nota aproximadamente dobrou de valor.

É interessante notar também a queda no valor de $\log_{10} (R_{\text{nonlin}})$ para $(d, \hat{d})$. Isto ocorreu pois o algoritmo empregado (com \textit{overlap-add}) não é estritamente linear; por exemplo, as últimas $L - 1$ amostras geradas na convolução de cada intervalo não são utilizadas no processo de estimação.\footnote{Se um sinal de comprimento $M$ é convoluído com um filtro de tamanho $L$, a saída resultante terá tamanho $M+L-1$. Porém, como a janela também tem tamanho $M$, foi necessário descartar as últimas $L-1$ amostras de cada iteração para realizarmos o \textit{overlap-add}.} Portanto, é possível que o método introduza não-linearidades indesejadas ao sinal de entrada. Mesmo assim, estas supostas distorções detectadas foram virtualmente inaudíveis.

\subsection{\textit{Fades} com ruído aditivo}
\label{subsec:wiener:experiment-2}

No segundo experimento, foi considerada exatamente a mesma versão distorcida do teste anterior. Porém, agora, à mixagem final foi somado o ruído; assim, o sinal distorcido foi usado como trilha de fundo para o diálogo. Com isso, avalia-se a robustez do método a sinais espúrios (com um caso extremo, já que o ruído está mais intenso que o sinal desejado). A SNR da observação é $-9.17$~dB. Os resultados encontram-se na Tabela~\ref{tab:wf:experiment-2}.
{\def\arraystretch{1.25}\tabcolsep=10pt
\begin{table}[!ht]
    \centering
    \caption[Resultados do segundo experimento: \textit{fades} com ruído aditivo]{Resultados do segundo experimento.}
    \label{tab:wf:experiment-2}
    \begin{tabular}{cccc}
        \toprule
                         & SDR        & PAQM (MOS)  & $\log_{10}(R_{\text{nonlin}})$ \\
        \midrule
        $(d, x)$       & $-11.57$ dB & $1.17$  & $-0.005$                 \\
        $(d, \hat{d})$ & $15.39$ dB & $1.20$   & $-0.028$                \\ \bottomrule
    \end{tabular}
\end{table}
}

Embora o algoritmo tenha melhorado as medidas, os valores pioraram quando comparados aos do experimento anterior. Isto era esperado, visto que a trilha descorrelacionada possuía maior energia na mixagem final. Deste modo, o método não conseguiu reproduzir igualmente bem o processamento aplicado ao sinal original, resultando principalmente em resquícios de ruído --- zumbidos ``metálicos'' --- nos instantes de maior intensidade no diálogo.

\subsection{\textit{Soft clipping}}

No terceiro experimento, queremos avaliar a eficiência do método em replicar a distorção não-linear de \textit{soft clipping}. No Audacity, a curva de limitação é uma função definida por partes: linear entre $-0.5$ e $0.5$ e senoidal nas extremidades (cada uma consiste em $1/8$ de um período de onda). A limitação é feita passando o sinal por este mapeamento, que antes é normalizado para que seu valor máximo seja igual ao pico de amplitude máximo especificado; no caso do experimento, este foi $-7.5$ dB. O ruído não foi introduzido. Os resultados encontram-se na Tabela~\ref{tab:wf:experiment-3}.
{\def\arraystretch{1.25}\tabcolsep=10pt
\begin{table}[!ht]
    \centering
    \caption[Resultados do terceiro experimento: \textit{soft clipping}]{Resultados do terceiro experimento.}
    \label{tab:wf:experiment-3}
    \begin{tabular}{cccc}
        \toprule
                         & SDR        & PAQM (MOS)  & $\log_{10}(R_{\text{nonlin}})$ \\
        \midrule
        $(d, x)$       & $19.56$ dB & $1.21$  & $-0.016$                 \\
        $(d, \hat{d})$ & $23.24$ dB & $1.22$ & $-0.016$                \\ \bottomrule
    \end{tabular}
\end{table}
}

Podemos observar uma pequena melhora nos valores da SDR e da PAQM, e nenhuma alteração no valor do $\log_{10}(R_{\text{nonlin}})$. Temos aqui o primeiro exemplo das limitações do Filtro de Wiener, que não consegue reproduzir a distorção não-linear aplicada ao sinal original; o incremento provavelmente se deu porque o algoritmo é capaz de aplicar uma atenuação aos picos, mas não um ceifamento.

\subsection{\textit{Soft clipping} com ruído aditivo}

Neste experimento, somamos a trilha de diálogo ao sinal fabricado no experimento anterior. É importante notar que não foi aplicado nenhum outro processamento ao sinal distorcido, portanto, a SNR está maior do que a encontrada no Experimento~\ref{subsec:wiener:experiment-2}, sendo $3.97$~dB. Os resultados encontram-se na Tabela~\ref{tab:wf:experiment-4}.
{\def\arraystretch{1.25}\tabcolsep=10pt
\begin{table}[!ht]
    \centering
    \caption[Resultados do quarto experimento: \textit{soft clipping} com ruído aditivo]{Resultados do quarto experimento.}
    \label{tab:wf:experiment-4}
    \begin{tabular}{cccc}
        \toprule
                         & SDR        & PAQM (MOS)  & $\log_{10}(R_{\text{nonlin}})$ \\
        \midrule
        $(d, x)$       & $19.56$ dB & $1.21$  & $-0.016$                 \\
        $(d, \hat{d})$ & $22.11$ dB & $1.20$ & $-0.022$                \\ \bottomrule
    \end{tabular}
\end{table}
}

Observe que, mesmo com a melhoria no valor da SDR, houve uma piora nos valores das outras duas medidas. Ao ouvir a estimação resultante, o porquê disso se torna evidente: novamente temos resquícios do diálogo em alguns instantes do sinal estimado, mas, além disso, possivelmente também artefatos do algoritmo, visto que, como demonstrado melhor no próximo experimento, o método é capaz de introduzir ruídos no sinal distorcido.

\subsection{\textit{Fades} e codificação com perdas}
\label{subsec:wiener:experiment-5}

Como o processo de codificação costuma ser executado ao fim de uma mixagem, após outras distorções terem sido aplicadas, iremos utilizar o sinal distorcido do primeiro experimento como entrada no algoritmo de codificação. A gravação de diálogo não foi adicionada. Foi aplicada uma codificação MP3 com taxa de bits constante de 56 kbps usando a biblioteca LAME\abbrev{LAME}{LAME \textit{Ain't an} MP3 \textit{Encoder}}~\cite{lame-encoder}. Os resultados encontram-se na Tabela~\ref{tab:wf:experiment-5}.
{\def\arraystretch{1.25}\tabcolsep=10pt
\begin{table}[!ht]
    \centering
    \caption[Resultados do quinto experimento: \textit{fades} e codificação com perdas]{Resultados do quinto experimento.}
    \label{tab:wf:experiment-5}
    \begin{tabular}{cccc}
        \toprule
                         & SDR        & PAQM (MOS)   & $\log_{10}(R_{\text{nonlin}})$ \\
        \midrule
        $(d, x)$       & $-14.77$ dB & $1.17$  & $-0.032$                 \\
        $(d, \hat{d})$ & $13.43$ dB & $1.18$ & $-0.080$                \\ \bottomrule
    \end{tabular}
\end{table}
}

É possível notar que, embora a SDR tenha ficado com um valor próximo ao do segundo experimento, a PAQM e o $\log_{10}(R_{\text{nonlin}})$ denunciam a baixa similaridade psicoacústica entre o sinal distorcido e o estimado (quando comparados aos outros resultados). Ademais, ao tentar reproduzir distorções não-lineares usando um sistema linear, o algoritmo introduziu artefatos na estimação, o que explica a queda significativa no valor de $\log_{10}(R_{\text{nonlin}})$.

\subsection{\textit{Fades} com ruído aditivo e codificação com perdas}
\label{subsec:wiener:experiment-6}

Para este último teste, codificou-se o áudio gerado no segundo experimento: o sinal $x[n]$ com \textit{fades} e diálogo somado. Os parâmetros da codificação foram os mesmos do quinto experimento. É importante mencionar que, neste caso, não é possível obter a versão isolada exata do sinal distorcido na observação, já que o processo de codificação, por ser não-linear, utiliza uma combinação não-trivial entre a entrada e o ruído. Por este motivo, como $d[n]$ usaremos o mesmo sinal distorcido gerado no Experimento~\ref{subsec:wiener:experiment-5}, que pressupomos ser \emph{aproximadamente} igual ao valor da versão do sinal presente em $y[n]$. Não foi possível calcular a SNR dessa observação, mas podemos estimar seu limite superior como sendo $-9.17$~dB. Os resultados encontram-se na Tabela~\ref{tab:wf:experiment-6}.
{\def\arraystretch{1.25}\tabcolsep=10pt
\begin{table}[!ht]
    \centering
    \caption[Resultados do sexto experimento: \textit{fades} com ruído aditivo e codificação com perdas]{Resultados do sexto experimento.}
    \label{tab:wf:experiment-6}
    \begin{tabular}{cccc}
        \toprule
                         & SDR        & PAQM (MOS)  & $\log_{10}(R_{\text{nonlin}})$ \\
        \midrule
        $(d, x)$       & $-14.77$ dB & $1.17$  & $-0.032$                 \\
        $(d, \hat{d})$ & $11.47$ dB & $1.18$ & $-0.087$                \\ \bottomrule
    \end{tabular}
\end{table}
}

Os resultados são a culminação de tudo que vimos até agora nos experimentos. Se, por um lado, o modelo consegue estimar a variação de amplitude, por outro, o processamento não-linear --- junto à baixa razão sinal-ruído --- dificulta a estimação, sendo isso refletido principalmente no quesito psicoacústico.